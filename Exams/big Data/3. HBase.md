# Apache HBase

## What is HBase?

### Definition
- **Industry-leading implementation** of Google's BigTable design
- **"Sparse, distributed, persistent multidimensional sorted map"** (Google's BigTable definition)
- **Open source Apache Top Level Project**
- **NoSQL data store** built on Hadoop ecosystem

### Real-World Usage
- Powers leading websites: **Facebook, Yahoo**, and others
- Designed for **big data applications** requiring fast access
- Part of **Hadoop ecosystem** integration

## Why Choose HBase?

### Key Advantages
1. **Highly Scalable**
   - Automatic partitioning (sharding)
   - Scale linearly and automatically with new nodes

2. **Low Latency**
   - Support for random read/write operations
   - Small range scan capabilities

3. **Highly Available**
   - Built-in fault tolerance
   - Automatic failover mechanisms

4. **Strong Consistency**
   - ACID properties at row level
   - Consistent data access

5. **Sparse Data Optimization**
   - No fixed columns required
   - Variable schema per row

## HBase Data Model

### Core Concepts
- **Data stored in tables** (like RDBMS)
- **Tables made of rows and columns**
- **All columns belong to column families**
- **Schema only defines column families** (not individual columns)

### Key Data Model Features
- **Large, variable number of columns per row**
- **Each cell value has a version** (timestamp)
- **Access pattern**: `(row key, column key, timestamp) → value`
- **Row storage**: Ordered by row keys
- **Row keys are byte arrays**: Lexicographically sorted

### Think "Map" Not Spreadsheet
- **Multidimensional sorted map** (not traditional column-oriented)
- **Key-value store** with versioning
- **Sparse data structure** - columns exist only when inserted

## HBase Data Model Components

### Table Structure
- **Table**: Contains column families
- **Column Family**: Logical and physical grouping of columns
- **Column**: 
  - Exists only when inserted
  - Can have multiple versions
  - Each row can have different set of columns
  - Identified by column key
- **Row Key**:
  - Implicit primary key
  - Used for storing ordered rows
  - Enables efficient queries

### Data Access Pattern
```
(row key, column family:column qualifier, timestamp) → value
```

## HBase vs Traditional RDBMS

### Key Differences

| Aspect | RDBMS | HBase |
|--------|-------|--------|
| **Schema** | Fixed schema required | No fixed schema (only column families) |
| **Columns** | Fixed columns per table | Variable columns per row |
| **Data Types** | Typed columns | All data as byte arrays |
| **Joins** | Complex joins supported | No joins (denormalized data) |
| **Transactions** | ACID across tables | Row-level atomicity only |
| **Scalability** | Vertical scaling | Horizontal scaling |
| **Query Language** | SQL | API-based access |

### Physical vs Logical View
- **Logical View**: Similar to traditional table structure
- **Physical View**: Each cell stored with full coordinates
- **Storage**: `(row key, column family, column qualifier, timestamp, value)`

## HBase Architecture

### Core Components

#### Region
- **Subset of table's rows** (horizontal partition)
- **Automatically sharded** when grown too large
- **Basic unit of scalability** and load balancing
- **Start row and end row** boundaries
- **Automatically split** when reaches specified size

#### Region Server
- **Hosts tables** and performs reads
- **Buffers writes** for performance
- **Clients communicate directly** for reads/writes
- **Multiple regions per server** possible
- **Load balanced** by Master

#### Master Server
- **Coordinates Region Servers**
- **Detects Region Server status**
- **Performs load balancing**
- **Assigns regions to Region Servers**
- **Not part of read/write path** (performance benefit)
- **Highly available** with ZooKeeper backup

**Master Server Responsibilities**:
- Monitor all Region Server instances
- Initialize Region Server failover
- Perform metadata changes (create table, etc.)
- Manage region assignment
- Background services:
  - **LoadBalancer**: Move regions to balance cluster load
  - **CatalogJanitor**: Check and clean up META table
  - **LogCleaner**: Clear old HLogs

#### ZooKeeper
- **Critical component** for HBase
- **Ensures one Master Server running**
- **Registers Region Servers**
- **Handles failures** (Region and Master Server)
- **Integral part** of fault-tolerant architecture

### Region Server Components

#### Write-Ahead Log (WAL)
- **Stores all edits** to the Store
- **One WAL per Region Server**
- **All edits entered first** in WAL (durability)

#### Region
- **Stores data** for certain region of table
- **Multiple Stores** per region

#### Store
- **Holds column family** in a region
- **Has MemStore** and zero or more HFiles
- **One Store per column family**

## Auto-Sharding and Scaling

### How Sharding Works
1. **Initially**: 1 Region per Table
2. **Growth**: When table exceeds configurable limit
3. **Split**: Automatically split in half (Auto-Sharding)
4. **Distribution**: Multiple Regions served by Region Servers
5. **Scaling**: Add more Region Servers as needed
6. **Assignment**: Master automatically assigns Regions

### Scaling Benefits
- **Linear scaling** with new nodes
- **Automatic load balancing**
- **No manual intervention** required
- **Transparent to applications**

## Read/Write Operations

### Write Process
1. Client sends write request to Region Server
2. Write logged to **WAL first** (durability)
3. Data written to **MemStore** (in-memory)
4. **Acknowledgment sent** to client
5. **Background flush** to HFiles on disk

### Read Process
1. Client sends read request to Region Server
2. Check **MemStore first** (latest data)
3. Check **HFiles** if not in MemStore
4. **Merge results** from multiple sources
5. **Return data** to client

## When to Use HBase

### Ideal Use Cases
- **Large amounts of data** (think Petabytes)
- **Efficient random access** inside large datasets
- **Need to scale gracefully**
- **Simple and fixed access patterns**
- **Sparse data model** (variable schema)
- **Row-level ACID** sufficient (no cross-table transactions)

### Specific Scenarios
- **Hundreds of millions or billions of rows**
- **<mark style="background: #FF5582A6;">Real-time</mark> random <mark style="background: #D2B3FFA6;">read/write**</mark> requirements
- **Variable schema** needs
- **<mark style="background: #FF5582A6;">High availability</mark>** requirements
- **Linear scaling** needs

## When NOT to Use HBase

### Avoid HBase When
- **<mark style="background: #FF5582A6;">Small datasets</mark>** (few thousand/million rows → use RDBMS)
- **Need RDBMS features**:
  - Typed columns
  - Secondary indexes
  - Complex transactions
  - Advanced query languages (SQL)
- **Insufficient hardware** (needs minimum 5 DataNodes + NameNode)
- **<mark style="background: #FF5582A6;">Complex relational queries</mark>** required
- **ACID properties across tables** needed

## ACID Properties in HBase

### Atomicity
- **Row-level atomicity** provided
- **No atomicity across rows** or tables

### Consistency and Isolation
- **Complete row consistency**: All rows returned via API consist of complete row that existed at some point
- **Row-level isolation**

### Durability
- **All visible data is durable**
- **Reads never return non-durable data**

### Concurrency Control
- **Automatic locking** before writes
- **Automatic lock release** after writes
- **Manual locking control** available to users

## HBase Shell Commands

### Table Operations
```bash
# Create table
create '<table_name>', '<column_family>'

# List tables
list

# Disable table
disable '<table_name>'
disable_all

# Enable table
enable '<table_name>'

# Describe table
describe '<table_name>'

# Alter table
alter 't1', NAME => 'f1', VERSIONS => 5

# Check table existence
exists '<table_name>'

# Drop table
drop '<table_name>'
```

### Data Operations
```bash
# Insert data
put '<table_name>', 'row1', '<colfamily:colname>', '<value>'

# Update data
put '<table_name>', 'row', 'column_family:column_name', 'new_value'

# Read data
get '<table_name>', 'row1'

# Read specific column
get '<table_name>', 'rowid', {COLUMN => 'column_family:column_name'}

# Delete specific cell
delete '<table_name>', '<row>', '<column_name>', '<timestamp>'

# Delete all cells in row
deleteall '<table_name>', '<row>'

# Scan table
scan '<table_name>'
```

## Key Architecture Benefits

### Performance
- **Direct client-server communication** for reads/writes
- **Master not in critical path**
- **In-memory MemStore** for fast writes
- **Efficient random access**

### Scalability
- **Automatic sharding** (regions)
- **Linear scaling** with hardware
- **Load balancing** across Region Servers
- **No single point of failure**

### Availability
- **Automatic failover**
- **ZooKeeper coordination**
- **Multiple Master backup**
- **Region reassignment** on failures

### Flexibility
- **Schema-less** (except column families)
- **Variable columns per row**
- **Versioned data**
- **Sparse data optimization**

## Key Exam Points to Remember

1. **HBase is Google BigTable implementation** - sparse, distributed, persistent multidimensional sorted map
2. **NoSQL <mark style="background: #FF5582A6;">key-value</mark> store** with versioning capabilities
3. <mark style="background: #FF5582A6;">**Row keys are byte arrays**</mark> - lexicographically sorted
4. **Only column families need to be defined** in schema
5. **Each cell has coordinates**: (row key, column family:qualifier, timestamp) → value
6. <mark style="background: #FF5582A6;">**Region is basic unit** of scalability</mark> and load balancing
7. **Auto-sharding**: Regions split automatically when too large
8. **<mark style="background: #ABF7F7A6;">Master Server not in read/write path</mark>** - performance benefit
9. **<mark style="background: #D2B3FFA6;">ZooKeeper</mark> critical** for coordination and fault tolerance
10. **WAL ensures durability** - all writes logged first
11. **Row-level atomicity only** - no cross-table transactions
12. **Use for petabyte-scale data** with random access needs
13. **Avoid for small datasets** or complex relational queries
14. **Minimum 5 DataNodes required** due to HDFS replication
15. **All data stored as byte arrays** - no typed columns